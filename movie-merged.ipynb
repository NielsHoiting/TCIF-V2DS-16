{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB\n",
    "This notebook contains the first few steps of the data science pipeline on a dataset containing movies.\n",
    "\n",
    "## Group\n",
    "V2H-Groep 1: Films (IMDB)\n",
    "- Niels Hoiting\n",
    "- Jari Oostrom\n",
    "- Yusuf Syakur\n",
    "\n",
    "## Research questions\n",
    "1. What is the correlation between the gender of actors and the popularity of the movie. How does this change overtime?\n",
    "2. What happens if we cluster this dataset, leaving out the genre variable?\n",
    "3. To what extend can you predict the gross of a movie based on its popularity on Facebook and IMDB?\n",
    "\n",
    "## Dataset\n",
    "movie information with duration, genres, languages, country, budget and gross;\n",
    "likes on facebook for director, main cast, total cast en the movie itself;\n",
    "score on IMDB and reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data collection\n",
    "Import needed libraries. The dataset is already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "df_movies = pd.read_csv('movie.csv')\n",
    "df_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data processing (Data munging)\n",
    "Look at the current dataframe and their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_movies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_movies.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current column order does not make sense. Order them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_movies = df_movies[['movie_imdb_link', 'movie_title', 'imdb_score', 'title_year', 'director_name', 'director_facebook_likes', 'actor_1_name',\n",
    "                      'actor_1_facebook_likes', 'actor_2_name', 'actor_2_facebook_likes', 'actor_3_name', 'actor_3_facebook_likes',\n",
    "                      'cast_total_facebook_likes', 'movie_facebook_likes', 'genres', 'budget', 'gross', 'country', 'language',\n",
    "                      'num_critic_for_reviews', 'num_user_for_reviews', 'num_voted_users', 'plot_keywords', 'color', 'content_rating',\n",
    "                      'duration', 'aspect_ratio', 'facenumber_in_poster']]\n",
    "df_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleaning\n",
    "\n",
    "Drop overall duplicates first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print('Before removing duplicates', df_movies.shape)\n",
    "df_movies = df_movies.drop_duplicates()\n",
    "print('After removing duplicates:', df_movies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 movie_imdb_link\n",
    "\n",
    "The movie_imdb_link duplicates only differ on a few columns like likes and votes. Extract the unique identifier from the URL and remove these duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pd.concat(gby_result for _, gby_result in df_movies.groupby(\"movie_imdb_link\") if len(gby_result) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_movies['movie_imdb_link'] = df_movies['movie_imdb_link'].str.extract(r'(?<=title\\/)(.*)(?=\\/\\?)', expand=False)\n",
    "print('Length before removing duplicates', df_movies.shape)\n",
    "df_movies = df_movies.drop_duplicates(subset='movie_imdb_link')\n",
    "print('Length after removing duplicates:',df_movies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 movie_title\n",
    "\n",
    "Strip whitespaces from both ends for the title. Duplicate movie_title rows might be a remake or a reboot of the movie. Leave them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_movies['movie_title'] = df_movies['movie_title'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 title_year\n",
    "Rows that have NaN for title_year are series/reviews, not movies. We won't need these for our analysis. CHange title_year to DateTime64 for time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_movies.loc[df_movies['title_year'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print('Length before removing NaN for title_year:', df_movies.shape)\n",
    "df_movies = df_movies.drop(df_movies.loc[df_movies['title_year'].isnull()].index)\n",
    "print('Length after removing NaN for title_year:', df_movies.shape)\n",
    "df_movies['title_year'] = pd.to_datetime(df_movies['title_year'], format='%Y', errors='coerce')\n",
    "df_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 actor_1_name\n",
    "Rows that have NaN for actor_1_name are documentaries, not movies. Remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_movies.loc[df_movies['actor_1_name'].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print('Length before removing NaN for actor_1_name:', df_movies.shape)\n",
    "df_movies = df_movies.drop(df_movies.loc[df_movies['actor_1_name'].isnull()].index)\n",
    "print('Length after removing NaN for actor_1_name:', df_movies.shape)\n",
    "df_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 genres\n",
    "\n",
    "Genres are split with an '|' delimeter. In total there are 28 unique genres. There are no NaN values. Split them and give them an own boolean column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "list_genres = list(set(itertools.chain.from_iterable(df_movies.genres.str.split('|'))))\n",
    "print(list_genres)\n",
    "\n",
    "def add_genre(df, genre):\n",
    "    genreConcat = 'genre_' + genre\n",
    "    df_copy = df.copy()\n",
    "    df_copy[genreConcat] = df_copy['genres'].str.contains(pat = genre)\n",
    "    return df_copy\n",
    "\n",
    "for genre in list_genres:\n",
    "    df_movies = add_genre(df_movies, genre)\n",
    "\n",
    "df_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 plot_keywords\n",
    "Remove '|' delimeter to able to use text mining (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_movies['plot_keywords'] = df_movies['plot_keywords'].str.replace('|', ' ')\n",
    "df_movies['plot_keywords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 content_rating\n",
    "Replace NaN and 'Unrated' with 'Not Rated'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(df_movies['content_rating'].unique())\n",
    "\n",
    "df_movies['content_rating'] = df_movies['content_rating'].str.replace('Unrated', 'Not Rated')\n",
    "df_movies['content_rating'] = df_movies['content_rating'].fillna(value='Not Rated')\n",
    "\n",
    "print(df_movies['content_rating'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 color\n",
    "All rows with NaN on color are released after 1990. Assume color is used (available since 1950s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_movies['color'] = df_movies['color'].fillna(value='Color')\n",
    "df_movies['color'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Remove unimportant NaN's\n",
    "\n",
    "Remove rows that have columns with NaN values. These NaN values can't be filled in by a 'default' value. Leave budget and gross (might turn out to be too much data loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print('Length before removing NaNs', len(df_movies))\n",
    "\n",
    "cols_to_ignore = ['movie_imdb_link', 'budget']\n",
    "df_budget_gross = df_movies[cols_to_ignore]\n",
    "df_movies = df_movies.drop(['budget'], axis=1)\n",
    "\n",
    "df_movies = df_movies.dropna()\n",
    "\n",
    "print('Length after removing NaNs', len(df_movies))\n",
    "\n",
    "df_movies = df_movies.join(df_budget_gross.set_index('movie_imdb_link'), on='movie_imdb_link')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10 Change to int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_movies = df_movies.astype({'director_facebook_likes': 'int64',\n",
    "                            'actor_1_facebook_likes': 'int64',\n",
    "                            'actor_2_facebook_likes': 'int64',\n",
    "                            'actor_3_facebook_likes': 'int64',\n",
    "                            'cast_total_facebook_likes': 'int64',\n",
    "                            'num_critic_for_reviews': 'int64',\n",
    "                            'num_user_for_reviews': 'int64',\n",
    "                            'num_voted_users': 'int64',\n",
    "                            'duration': 'int64',\n",
    "                            'facenumber_in_poster': 'int64',\n",
    "                              'gross': 'float64'})\n",
    "\n",
    "df_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and see if there is a correlation between budget and duration. Set a limit on budget to see a clear scatterplot. Looking at the result, there is no obvious correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(10,10))\n",
    "\n",
    "y_budget = df_movies[['budget']]\n",
    "x_duration = df_movies[['duration']]\n",
    "\n",
    "axScatter = plt.subplot(111)\n",
    "axScatter.scatter(x_duration, y_budget)\n",
    "plt.ylim(0, 300000000)\n",
    "axScatter.set_title('Scatterplot between budget and duration')\n",
    "axScatter.set_xlabel('Duration in minutes')\n",
    "axScatter.set_ylabel('Budget in US Dollars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add another dataset to see the gender of every actor.\n",
    "Both datasets come from the same source: The Movie Database. \n",
    "So we'll join them on the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_credits = pd.read_csv('tmdb_5000_credits.csv')\n",
    "df_credits = df_credits.rename(columns={'title': 'movie_title'})\n",
    "df_credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "movie_with_cast = pd.merge(df_movies, df_credits, how=\"inner\", on=\"movie_title\")\n",
    "movie_with_cast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast is a nested field, this function will return the gender for the given cast and name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def actor_to_gender(cast, name):\n",
    "    cast = json.loads(cast)\n",
    "    for actor in cast:\n",
    "        if name == actor['name']:\n",
    "            return actor['gender']\n",
    "    return 0\n",
    " \n",
    "movie_with_cast['actor_1_gender'] = movie_with_cast.apply(lambda movie: actor_to_gender(movie.cast, movie.actor_1_name), axis=1)\n",
    "movie_with_cast['actor_2_gender'] = movie_with_cast.apply(lambda movie: actor_to_gender(movie.cast, movie.actor_2_name), axis=1)\n",
    "movie_with_cast['actor_3_gender'] = movie_with_cast.apply(lambda movie: actor_to_gender(movie.cast, movie.actor_3_name), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "movie_with_cast.actor_1_gender.value_counts().plot(kind='pie', labels=['Male', 'Female', 'Unknown'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "movie_with_cast.actor_2_gender.value_counts().plot(kind='pie', labels=['Male', 'Female', 'Unknown'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "movie_with_cast.actor_3_gender.value_counts().plot(kind='pie', labels=['Male', 'Female', 'Unknown'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gender ratio is for the majority the same among the first three featured actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "plt_scatter = scatter_matrix(df_movies[['gross', 'num_critic_for_reviews', 'num_user_for_reviews', 'imdb_score', 'movie_facebook_likes']], alpha=0.2, figsize=(9,9), diagonal='kde').view()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To what extend can you predict the gross of a movie based on its popularity on Facebook and IMDB?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First we will determine how the gross is impacted by all the factors, then we will see what the best (most accurate) formula is.\n",
    "The factors we want to check are \n",
    "1. number of critic reviews\n",
    "2. number of user reviews\n",
    "3. movie facebook likes\n",
    "4. imdb score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% clean up data for the columns we'll be using\n"
    }
   },
   "outputs": [],
   "source": [
    "df_movies.replace([np.inf, -np.inf], np.nan).dropna(subset=['num_critic_for_reviews','num_user_for_reviews', 'movie_facebook_likes', 'imdb_score','gross'], how=\"all\")\n",
    "df_movies = df_movies.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a Python list of feature names\n",
    "feature_cols = ['num_critic_for_reviews','num_user_for_reviews', 'movie_facebook_likes', 'imdb_score',]\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X = df_movies[feature_cols]\n",
    "\n",
    "\n",
    "# print the first 5 rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# select a Series from the DataFrame\n",
    "y = df_movies['gross']\n",
    "\n",
    "# print the first 5 values\n",
    "y.head()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we start the model on all the different variables to create a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll look at the metrics of our formula, and how accurate it is, we do this by looking at the intercept and\n",
    "coefficient, and calculate the root mean squared error with the testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(linreg.intercept_)\n",
    "print(linreg.coef_)\n",
    "list(zip(feature_cols, linreg.coef_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', linreg.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mse)\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.math.sqrt(mse))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not good, a value of close to 1 is ideal, this is extremely high. We'll drop the columns that seem to have the least correlation according to the scatter plot.\n",
    "We will drop number of critics for review as it seems to have the least correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a Python list of feature names\n",
    "feature_cols_2 = ['movie_facebook_likes', 'imdb_score','num_user_for_reviews']\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X_2 = df_movies[feature_cols_2]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate\n",
    "linreg_2 = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "print(linreg_2.intercept_)\n",
    "print(linreg_2.coef_)\n",
    "list(zip(feature_cols_2, linreg_2.coef_))\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred_2 = linreg_2.predict(X_test_2)\n",
    "mse = mean_squared_error(y_test_2, y_pred_2)\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', linreg_2.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mse)\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.math.sqrt(mse))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a good result, we want something not very far from 0, it even went up a slight bit. Let's drop even more columns, this time we'll remove number of user reviews and look again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a Python list of feature names\n",
    "feature_cols_3 = ['movie_facebook_likes', 'imdb_score',]\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X_3 = df_movies[feature_cols_3]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate\n",
    "linreg_3 = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg_3.fit(X_train_3, y_train_3)\n",
    "\n",
    "print(linreg_3.intercept_)\n",
    "print(linreg_3.coef_)\n",
    "list(zip(feature_cols_3, linreg_3.coef_))\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred_3 = linreg_3.predict(X_test_3)\n",
    "mse = mean_squared_error(y_test_3, y_pred_3)\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', linreg_3.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mse)\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.math.sqrt(mse))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test_3, y_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems dropping columns is not the answer, our first prediction is still the best, but it's definitely a large margin of error.\n",
    "It would seem that the correlation is weak at best, and removing columns is not a solution to the problem. Popularity on IMDB and facebook seems like\n",
    "a weak indicator for how well a movie will do financially.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Z-toets IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een filmcriticus stelt dat de score van engelstalige films lager is dan gemiddeld.\n",
    "\n",
    "Onderzoek met de dataset of deze filmcriticus gelijk heeft. Neem een steekproef (met ```pandas.DataFrame.sample(n=100,random_state=1)```) van 100 engelstalige films en beschouw de hele dataset als populatie. Neem als betrouwbaarheid 90%. Gebruik van de dataset alleen de filmgegevens waarbij zowel de taal (`language`) als de score (`imdb_score`) bekend zijn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movie.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_movies = movies[movies.imdb_score.notnull()]\n",
    "all_movies = all_movies[all_movies.language.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "movies_english = all_movies[all_movies.language == 'English']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample = movies_english.sample(n=100,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample.boxplot(column=\"imdb_score\")\n",
    "plt.show()\n",
    "all_movies.boxplot(column=\"imdb_score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample.imdb_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_movies.imdb_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stdev_en = st.tstd(sample[\"imdb_score\"])\n",
    "\n",
    "print(stdev_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the accuracy of our findings we have to do a Z-test. We will set out our hypothesis and null hypothesis and test the latter.\n",
    "\n",
    "These are as follows:\n",
    "\n",
    "H0 = English films score as well or better than other movies on IMDB. μother <= μenglish = 6.35\n",
    "\n",
    "H1 = English films score significantly worse than other movies on IMDB. μother > μenglish = 6.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "good_score = movies_english[movies_english.imdb_score >= all_movies.imdb_score.mean()].count()\n",
    "q = .5\n",
    "z_alpha = 1.29\n",
    "mean_english_score = sample.imdb_score.mean()\n",
    "mean_score = all_movies.imdb_score.mean()\n",
    "\n",
    "se = stdev_en / (np.sqrt(n))\n",
    "\n",
    "z = (mean_score - mean_english_score) / se\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The z value we found from the calculation is 0.68, this is significantly lower than the value we'd want of 1.29 or higher, \n",
    "we can therefore not reject the nul hypothesis, and not prove the alternative hypothesis either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "The z value we found from the calculation is 0.68, this is significantly lower than the value we'd want of 1.29 or higher, \n",
    "we can therefore not reject the nul hypothesis, and not prove the alternative hypothesis either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# select a Series from the DataFrame\n",
    "y = df_movies['gross']\n",
    "\n",
    "# print the first 5 values\n",
    "y.head()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we start the model on all the different variables to create a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll look at the metrics of our formula, and how accurate it is, we do this by looking at the intercept and\n",
    "coefficient, and calculate the root mean squared error with the testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(linreg.intercept_)\n",
    "print(linreg.coef_)\n",
    "list(zip(feature_cols, linreg.coef_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', linreg.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mse)\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.math.sqrt(mse))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is not good, a value of close to 1 is ideal, this is extremely high. We'll drop the columns that seem to have the least correlation according to the scatter plot.\n",
    "We will drop number of critics for review as it seems to have the least correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a Python list of feature names\n",
    "feature_cols_2 = ['movie_facebook_likes', 'imdb_score','num_user_for_reviews']\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X_2 = df_movies[feature_cols_2]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate\n",
    "linreg_2 = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "print(linreg_2.intercept_)\n",
    "print(linreg_2.coef_)\n",
    "list(zip(feature_cols_2, linreg_2.coef_))\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred_2 = linreg_2.predict(X_test_2)\n",
    "mse = mean_squared_error(y_test_2, y_pred_2)\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', linreg_2.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mse)\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.math.sqrt(mse))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is not a good result, we want something not very far from 0, it even went up a slight bit. Let's drop even more columns, this time we'll remove number of user reviews and look again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a Python list of feature names\n",
    "feature_cols_3 = ['movie_facebook_likes', 'imdb_score',]\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X_3 = df_movies[feature_cols_3]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate\n",
    "linreg_3 = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg_3.fit(X_train_3, y_train_3)\n",
    "\n",
    "print(linreg_3.intercept_)\n",
    "print(linreg_3.coef_)\n",
    "list(zip(feature_cols_3, linreg_3.coef_))\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred_3 = linreg_3.predict(X_test_3)\n",
    "mse = mean_squared_error(y_test_3, y_pred_3)\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', linreg_3.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mse)\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.math.sqrt(mse))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test_3, y_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "It seems dropping columns is not the answer, our first prediction is still the best, but it's definitely a large margin of error.\n",
    "It would seem that the correlation is weak at best, and removing columns is not a solution to the problem. Popularity on IMDB and facebook seems like\n",
    "a weak indicator for how well a movie will do financially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
